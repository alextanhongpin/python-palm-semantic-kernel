{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86f09d8-0108-490a-8ed4-3651b962076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "api_key = os.environ[\"PALM_API_KEY\"]\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e468261-cf4e-4e80-a7cf-795b3c1be20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextanhongpin/Documents/python/python-palm-semantic-kernel/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x123ed3c90>,\n",
       " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x123ed3390>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import semantic_kernel.connectors.ai.google_palm as sk_gp\n",
    "import semantic_kernel.connectors.ai.hugging_face as sk_hf\n",
    "\n",
    "kernel = sk.Kernel(log=logger)\n",
    "kernel.add_text_completion_service(\n",
    "    \"models/text-bison-001\",\n",
    "    sk_gp.GooglePalmTextCompletion(\"models/text-bison-001\", api_key),\n",
    ")\n",
    "# NOTE: Inaccurate results when using this.\n",
    "# kernel.add_text_embedding_generation_service(\n",
    "#     \"models/embedding-gecko-001\",\n",
    "#     sk_gp.GooglePalmTextEmbedding(\"models/embedding-gecko-001\", api_key),\n",
    "# )\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"BAAI/bge-small-en-v1.5\", sk_hf.HuggingFaceTextEmbedding(\"BAAI/bge-small-en-v1.5\")\n",
    ")\n",
    "# kernel.add_text_embedding_generation_service(\n",
    "#     \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "#     sk_hf.HuggingFaceTextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "# )\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa56fd32-e2b4-496d-9e8f-ad345e44c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def populate_memory(kernel: sk.Kernel) -> None:\n",
    "    # Add some documents to the semantic memory\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"aboutMe\", id=\"info1\", text=\"My name is Andrea\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"aboutMe\", id=\"info2\", text=\"I currently work as a tour guide\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"aboutMe\", id=\"info3\", text=\"I've been living in Seattle since 2005\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"aboutMe\", id=\"info4\", text=\"I visited France and Italy five times since 2015\"\n",
    "    )\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"aboutMe\", id=\"info5\", text=\"My family is from New York\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3aa487-8088-4e08-b7f1-97e621c3aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "await populate_memory(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75bca0a-dfac-42d4-9e39-93aea1232c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel) -> None:\n",
    "    questions = [\n",
    "        \"what's my name\",\n",
    "        \"where do I live?\",\n",
    "        \"where's my family from?\",\n",
    "        \"where have I traveled?\",\n",
    "        \"what do I do for work\",\n",
    "    ]\n",
    "    for question in questions:\n",
    "        print(f\"Question: {question}\")\n",
    "        result = await kernel.memory.search_async(\"aboutMe\", question)\n",
    "        print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088048d8-7a73-47c3-abd9-fd77d508bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what's my name\n",
      "Answer: My name is Andrea\n",
      "\n",
      "Question: where do I live?\n",
      "Answer: I've been living in Seattle since 2005\n",
      "\n",
      "Question: where's my family from?\n",
      "Answer: My family is from New York\n",
      "\n",
      "Question: where have I traveled?\n",
      "Answer: I currently work as a tour guide\n",
      "\n",
      "Question: what do I do for work\n",
      "Answer: I currently work as a tour guide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await search_memory_examples(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b3782f-2f2d-40f9-a94d-3beb626a1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_chat_with_memory(\n",
    "    kernel: sk.Kernel,\n",
    ") -> Tuple[sk.SKFunctionBase, sk.SKContext]:\n",
    "    sk_prompt = \"\"\"\n",
    "    ChatBot can have a conversation with you about any topic.\n",
    "    It can give explicit instructions or say 'I don't know' if\n",
    "    it does not have an answer.\n",
    "    \n",
    "    Information about me, from previous conversations:\n",
    "    - {{$fact1}} {{recall $fact1}}\n",
    "    - {{$fact2}} {{recall $fact2}}\n",
    "    - {{$fact3}} {{recall $fact3}}\n",
    "    - {{$fact4}} {{recall $fact4}}\n",
    "    - {{$fact5}} {{recall $fact5}}\n",
    "    \n",
    "    Chat:\n",
    "    {{$chat_history}}\n",
    "    User: {{$user_input}}\n",
    "    ChatBot: \"\"\".strip()\n",
    "\n",
    "    chat_func = kernel.create_semantic_function(\n",
    "        sk_prompt, max_tokens=200, temperature=0.8\n",
    "    )\n",
    "\n",
    "    context = kernel.create_new_context()\n",
    "    context[\"fact1\"] = \"what is my name?\"\n",
    "    context[\"fact2\"] = \"where do I live?\"\n",
    "    context[\"fact3\"] = \"where's my family from?\"\n",
    "    context[\"fact4\"] = \"where have I traveled?\"\n",
    "    context[\"fact5\"] = \"what do I do for work?\"\n",
    "\n",
    "    context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"aboutMe\"\n",
    "    # The RelevanceParam is used in memory search and is a measure of the relevance score\n",
    "    # from 0.0 to 1.0, where 1.0 means a perfect match.\n",
    "    context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
    "\n",
    "    context[\"chat_history\"] = \"\"\n",
    "\n",
    "    return chat_func, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b914e267-cb54-4fdb-9e10-fe5b2c62dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(\n",
    "    kernel: sk.Kernel, chat_func: sk.SKFunctionBase, context: sk.SKContext\n",
    ") -> bool:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "        context[\"user_input\"] = user_input\n",
    "        print(f\"User:> {user_input}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    answer = await kernel.run_async(chat_func, input_vars=context.variables)\n",
    "    context[\"chat_history\"] += f\"\\nUser:> {user_input}\\nChatBot:> {answer}\\n\"\n",
    "\n",
    "    print(f\"ChatBot:> {answer}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130a85c2-b8c3-4ee0-9029-85322499d438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating memory...\n",
      "Asking questions... (manually)\n",
      "Question: what's my name\n",
      "Answer: My name is Andrea\n",
      "\n",
      "Question: where do I live?\n",
      "Answer: I've been living in Seattle since 2005\n",
      "\n",
      "Question: where's my family from?\n",
      "Answer: My family is from New York\n",
      "\n",
      "Question: where have I traveled?\n",
      "Answer: I currently work as a tour guide\n",
      "\n",
      "Question: what do I do for work\n",
      "Answer: I currently work as a tour guide\n",
      "\n",
      "Setting up a chat (with memory!)\n",
      "Begin chatting (type 'exit' to exit):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:>  name the places I travelled to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Variable `$chat_history` not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> name the places I travelled to\n",
      "ChatBot:> You have traveled to New York, Las Vegas, and Paris.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:>  wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n",
      "WARNING:root:Memory not found in collection: aboutMe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> wrong\n",
      "ChatBot:> > I don't know.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> exit\n",
      "\n",
      "\n",
      "Exiting chat...\n"
     ]
    }
   ],
   "source": [
    "print(\"Populating memory...\")\n",
    "await populate_memory(kernel)\n",
    "\n",
    "print(\"Asking questions... (manually)\")\n",
    "await search_memory_examples(kernel)\n",
    "\n",
    "print(\"Setting up a chat (with memory!)\")\n",
    "chat_func, context = await setup_chat_with_memory(kernel)\n",
    "\n",
    "print(\"Begin chatting (type 'exit' to exit):\\n\")\n",
    "chatting = True\n",
    "while chatting:\n",
    "    chatting = await chat(kernel, chat_func, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09844e65-faf8-4464-a0d9-7bce0d024a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
